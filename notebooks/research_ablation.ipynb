{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Research Notebook: Why LB Is Bad and What To Fix\n",
        "\n",
        "This notebook is for **diagnostics-first** iterations on anti-fraud ranking.\n",
        "\n",
        "Focus:\n",
        "- validation mismatch (weekly vs last-day)\n",
        "- label strategy / unlabeled impact\n",
        "- leakage risk in graph-risk / sequence features\n",
        "- representation gap between offline AP and leaderboard behavior\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment Matrix (6 runs)\n",
        "\n",
        "1. Base (time + amount)\n",
        "2. Base + sequence\n",
        "3. Base + graph-risk\n",
        "4. Base + sequence + graph-risk\n",
        "5. (red+yellow only) Base + sequence + graph-risk\n",
        "6. (red+yellow only) + count-only graph features (no target-mean risk)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import subprocess\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "ROOT = Path('/workspace/competition')\n",
        "RUNS_DIR = ROOT / 'artifacts' / 'runs'\n",
        "RUNS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "FAST_MODE = True  # set False for full runs\n",
        "MAX_LABELED = 20000 if FAST_MODE else None\n",
        "MAX_UNLABELED = 20000 if FAST_MODE else None\n",
        "MAX_TEST = 50000 if FAST_MODE else None\n",
        "\n",
        "BASE_CMD = [\n",
        "    'python', 'scripts/train_baseline.py',\n",
        "    '--config', 'conf/pipeline.yaml',\n",
        "    '--device', 'cuda',\n",
        "]\n",
        "\n",
        "def run_exp(name, extra_args):\n",
        "    cmd = BASE_CMD + ['--run-name', name] + extra_args\n",
        "    if MAX_LABELED is not None:\n",
        "        cmd += ['--max-labeled-rows', str(MAX_LABELED)]\n",
        "    if MAX_UNLABELED is not None:\n",
        "        cmd += ['--max-unlabeled-rows', str(MAX_UNLABELED)]\n",
        "    if MAX_TEST is not None:\n",
        "        cmd += ['--max-test-rows', str(MAX_TEST)]\n",
        "    print('RUN:', ' '.join(cmd))\n",
        "    p = subprocess.run(cmd, cwd=ROOT, text=True, capture_output=True)\n",
        "    print(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        print(p.stderr)\n",
        "        raise RuntimeError(f'Run failed: {name}')\n",
        "\n",
        "def load_summary(name):\n",
        "    p = RUNS_DIR / name / 'summary.json'\n",
        "    if not p.exists():\n",
        "        return None\n",
        "    return json.loads(p.read_text())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "experiments = [\n",
        "    # run_name, feature_desc, extra_args\n",
        "    ('res_01_base', 'base', [\n",
        "        '--disable-sequence', '--disable-pretrain-profile', '--graph-risk-mode', 'off'\n",
        "    ]),\n",
        "    ('res_02_base_seq', 'base+sequence', [\n",
        "        '--disable-pretrain-profile', '--graph-risk-mode', 'off'\n",
        "    ]),\n",
        "    ('res_03_base_graph', 'base+graph', [\n",
        "        '--disable-sequence', '--disable-pretrain-profile', '--graph-risk-mode', 'full'\n",
        "    ]),\n",
        "    ('res_04_base_seq_graph', 'base+sequence+graph', [\n",
        "        '--disable-pretrain-profile', '--graph-risk-mode', 'full'\n",
        "    ]),\n",
        "    ('res_05_ry_only', 'red+yellow only + sequence+graph', [\n",
        "        '--disable-pretrain-profile', '--graph-risk-mode', 'full', '--use-unlabeled', 'false'\n",
        "    ]),\n",
        "    ('res_06_ry_count_only', 'red+yellow only + sequence + graph-count-only', [\n",
        "        '--disable-pretrain-profile', '--graph-risk-mode', 'count', '--use-unlabeled', 'false'\n",
        "    ]),\n",
        "]\n",
        "experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# WARNING: this can take time.\n",
        "# Uncomment to run all experiments:\n",
        "\n",
        "# for name, _, extra in experiments:\n",
        "#     run_exp(name, extra)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = []\n",
        "for name, feature_desc, _ in experiments:\n",
        "    s = load_summary(name)\n",
        "    if s is None:\n",
        "        continue\n",
        "    rows.append({\n",
        "        'run': name,\n",
        "        'features': feature_desc,\n",
        "        'train_rows': s.get('train_rows'),\n",
        "        'include_unlabeled': s.get('include_unlabeled'),\n",
        "        'weight_unlabeled_ratio': s.get('weight_unlabeled_ratio'),\n",
        "        'AP_labeled': s.get('cv_ap_labeled_mean'),\n",
        "        'AP_proxy_week': s.get('cv_ap_proxy_mean'),\n",
        "        'AP_lastday': s.get('cv_ap_proxy_lastday_mean'),\n",
        "        'graph_risk_mode': s.get('graph_risk_mode'),\n",
        "        'sequence': s.get('use_sequence'),\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows).sort_values('AP_lastday', ascending=False)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save comparable table for sharing\n",
        "out = ROOT / 'artifacts' / 'research_ablation_table.csv'\n",
        "if 'df' in globals() and len(df) > 0:\n",
        "    df.to_csv(out, index=False)\n",
        "    print('saved:', out)\n",
        "else:\n",
        "    print('no rows yet')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Leakage / Mismatch Checklist\n",
        "\n",
        "- If `AP_proxy_week` is high but `AP_lastday` is low, CV still mismatches LB-like setup.\n",
        "- If `graph` runs collapse vs sequence-only, inspect target-based graph risk leakage/overfit.\n",
        "- If turning off unlabeled improves AP_lastday, current green sampling introduces bias.\n",
        "- If train-like AP is fine but LB is poor, switch optimization target to last-day slice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect one run in detail\n",
        "RUN = 'res_04_base_seq_graph'\n",
        "fold_path = RUNS_DIR / RUN / 'fold_metrics.csv'\n",
        "if fold_path.exists():\n",
        "    display(pd.read_csv(fold_path))\n",
        "else:\n",
        "    print('run not found:', RUN)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}